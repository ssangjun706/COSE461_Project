{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if root not in sys.path:\n",
    "    sys.path.append(root)\n",
    "\n",
    "from src.hf_utils import list_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mistralai/Mistral-Small-3.1-24B-Instruct-2503',\n",
       " 'meta-llama/Llama-3.3-70B-Instruct']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f43ce7e10a489cbd30275e58d38430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "import torch\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "device = \"cuda\"\n",
    "checkpoint = \"mistralai/Mistral-Small-3.1-24B-Instruct-2503\"\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    checkpoint, device_map=\"auto\", torch_dtype=torch.bfloat16\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(checkpoint)\n",
    "\n",
    "text = processor(\n",
    "    text=\"Can you tell me about the weather in Tokyo?\", return_tensors=\"pt\"\n",
    ").to(device, dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "generate_ids = model.generate(**text, max_new_tokens=250, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 13 12:59:30 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 575.51.03              Driver Version: 575.51.03      CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX A6000               Off |   00000000:1B:00.0 Off |                  Off |\n",
      "| 30%   32C    P8             17W /  300W |   22688MiB /  49140MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA RTX A6000               Off |   00000000:1E:00.0 Off |                  Off |\n",
      "| 30%   36C    P8             26W /  300W |   23955MiB /  49140MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA RTX A6000               Off |   00000000:21:00.0 Off |                  Off |\n",
      "| 30%   33C    P8             14W /  300W |      35MiB /  49140MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA RTX A6000               Off |   00000000:22:00.0 Off |                  Off |\n",
      "| 30%   33C    P8             25W /  300W |      35MiB /  49140MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   4  NVIDIA RTX A6000               Off |   00000000:98:00.0 Off |                  Off |\n",
      "| 30%   35C    P8             17W /  300W |      35MiB /  49140MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   5  NVIDIA RTX A6000               Off |   00000000:9B:00.0 Off |                  Off |\n",
      "| 30%   33C    P8             22W /  300W |      35MiB /  49140MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   6  NVIDIA RTX A6000               Off |   00000000:9F:00.0 Off |                  Off |\n",
      "| 30%   29C    P8             28W /  300W |      35MiB /  49140MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2007      G   /usr/lib/xorg/Xorg                       25MiB |\n",
      "|    0   N/A  N/A            2183      G   /usr/bin/gnome-shell                      4MiB |\n",
      "|    0   N/A  N/A          218774      C   ...E461_Project/.venv/bin/python      22630MiB |\n",
      "|    1   N/A  N/A            2007      G   /usr/lib/xorg/Xorg                       23MiB |\n",
      "|    1   N/A  N/A          218774      C   ...E461_Project/.venv/bin/python      23912MiB |\n",
      "|    2   N/A  N/A            2007      G   /usr/lib/xorg/Xorg                       23MiB |\n",
      "|    3   N/A  N/A            2007      G   /usr/lib/xorg/Xorg                       23MiB |\n",
      "|    4   N/A  N/A            2007      G   /usr/lib/xorg/Xorg                       23MiB |\n",
      "|    5   N/A  N/A            2007      G   /usr/lib/xorg/Xorg                       23MiB |\n",
      "|    6   N/A  N/A            2007      G   /usr/lib/xorg/Xorg                       23MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.system(\"nvidia-smi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_output = processor.batch_decode(\n",
    "    generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can you tell me about the weather in Tokyo? Japan? I would like to be able to talk about it. What is the average temperature? What are the main seasons?\n",
      "\n",
      "Tokyo has four distinct seasons: spring, summer, autumn, and winter. Each season offers a unique experience, so let's dive into what you can expect from the weather in Tokyo throughout the year.\n",
      "\n",
      "Here's a brief overview of the average temperatures and characteristics of each season:\n",
      "\n",
      "1. **Spring (March to May)**\n",
      "   - Average temperature: 50-73°F (10-23°C)\n",
      "   - Spring in Tokyo is mild and pleasant, with cherry blossom season (sakura) typically occurring in late March to early April. It's a popular time for visitors, but the weather can be a bit unpredictable, with occasional rain showers.\n",
      "\n",
      "2. **Summer (June to August)**\n",
      "   - Average temperature: 73-88°F (23-31°C)\n",
      "   - Summer in Tokyo is hot and humid, with temperatures often exceeding 90°F (32°C). This season also brings the rainy period (tsuyu) from early June to mid-July, followed by a humid and hot August. Typhoons may also occur during this\n"
     ]
    }
   ],
   "source": [
    "print(decoded_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
