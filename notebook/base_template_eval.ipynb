{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-23 07:56:57 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import Any\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if root not in sys.path:\n",
    "    sys.path.append(root)\n",
    "\n",
    "from src.model import APIServer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(\n",
    "    data: str,\n",
    "    target: str,\n",
    "    target_values: list[str],\n",
    ") -> list[str]:\n",
    "    target_values = \" or \".join(target_values)\n",
    "\n",
    "    def build_meta_prompt(X_data: Any) -> str:\n",
    "        return f\"\"\"Based on the input data, predict the value of '{target}':\n",
    "\n",
    "{X_data}\n",
    "\n",
    "**IMPORTANT: Respond with ONLY {target_values}. Do not include any explanations, reasoning, or additional text.\"\n",
    "\"\"\"\n",
    "\n",
    "    return list(map(build_meta_prompt, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(text: str) -> str:\n",
    "    match = re.search(r\"(DEAD|ALIVE)\", text)\n",
    "    if match and len(match.groups()) == 1:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return \"ERROR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        path: str,\n",
    "        train: bool = True,\n",
    "        shuffle: bool = True,\n",
    "        train_size: float = 0.8,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.target = \"Survived\"\n",
    "        self.target_values = [\"DEAD\", \"ALIVE\"]\n",
    "\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "        assert (\n",
    "            self.target in df.columns\n",
    "        ), f\"Target column '{self.target}' not found in the dataframe.\"\n",
    "\n",
    "        self.feature_labels = df.drop(columns=[self.target]).columns.tolist()\n",
    "\n",
    "        X = df.drop(columns=[self.target])\n",
    "        y = df[self.target]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            train_size=train_size,\n",
    "            random_state=42,\n",
    "            shuffle=shuffle,\n",
    "            stratify=y,\n",
    "        )\n",
    "\n",
    "        self.X = X_train if train else X_test\n",
    "        self.y = y_train if train else y_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X_dict = str(self.X.iloc[idx].to_dict())\n",
    "        y_value = self.target_values[self.y.iloc[idx].item()]\n",
    "        return X_dict, y_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:51<00:00,  1.15s/it]\n",
      "100%|██████████| 45/45 [00:51<00:00,  1.15s/it]\n",
      "100%|██████████| 45/45 [00:51<00:00,  1.15s/it]\n",
      "100%|██████████| 45/45 [00:51<00:00,  1.15s/it]\n",
      "100%|██████████| 45/45 [00:51<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy: [0.6145251396648045, 0.6703910614525139, 0.664804469273743, 0.6256983240223464, 0.6536312849162011]\n",
      "Total Error Rate: [0.12290502793296089, 0.055865921787709494, 0.09497206703910614, 0.0782122905027933, 0.11173184357541899]\n",
      "Average Accuracy: 0.6458100558659218\n",
      "Average Error Rate: 0.09273743016759776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = TitanicDataset(\"../dataset/titanic-dataset.csv\", train=False)\n",
    "data_loader = DataLoader(dataset, batch_size=4, shuffle=False)\n",
    "api_server = APIServer(\"localhost\", port=23456)\n",
    "num_epochs = 5\n",
    "\n",
    "total_accuracy = []\n",
    "total_error_rate = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    corrects = 0\n",
    "    errors = 0\n",
    "    for X, y in tqdm(data_loader):\n",
    "        prompts = process(X, \"Survived\", [\"DEAD\", \"ALIVE\"])\n",
    "        responses = api_server.request(prompts, {\"n\": 1})\n",
    "        y_preds = [parse(response) for response in responses]\n",
    "        errors += sum([1 if preds == \"ERROR\" else 0 for preds in y_preds])\n",
    "        corrects += sum([1 if a == b else 0 for a, b in zip(y_preds, y)])\n",
    "\n",
    "    total_accuracy.append(corrects / len(data_loader.dataset))\n",
    "    total_error_rate.append(errors / len(data_loader.dataset))\n",
    "\n",
    "print(\"Total Accuracy:\", total_accuracy)\n",
    "print(\"Total Error Rate:\", total_error_rate)\n",
    "\n",
    "print(f\"Average Accuracy: {sum(total_accuracy) / num_epochs}\")\n",
    "print(f\"Average Error Rate: {sum(total_error_rate) / num_epochs}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
