{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-24 06:45:19 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import Any\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if root not in sys.path:\n",
    "    sys.path.append(root)\n",
    "\n",
    "from src.inference import InferenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(\n",
    "    data: str,\n",
    "    target: str,\n",
    "    target_values: list[str],\n",
    ") -> list[str]:\n",
    "    target_values = \" or \".join(target_values)\n",
    "\n",
    "    def build_meta_prompt(X_data: Any) -> str:\n",
    "        return f\"\"\"Based on the input data, predict the value of '{target}':\n",
    "\n",
    "{X_data}\n",
    "\n",
    "**IMPORTANT: Respond with ONLY {target_values}. Do not include any explanations, reasoning, or additional text.\"\n",
    "\"\"\"\n",
    "\n",
    "    return list(map(build_meta_prompt, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(text: str) -> str:\n",
    "    match = re.search(r\"(DEAD|ALIVE)\", text)\n",
    "    if match and len(match.groups()) == 1:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return \"ERROR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        path: str,\n",
    "        train: bool = True,\n",
    "        shuffle: bool = True,\n",
    "        train_size: float = 0.8,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.target = \"Survived\"\n",
    "        self.target_values = [\"DEAD\", \"ALIVE\"]\n",
    "\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "        assert (\n",
    "            self.target in df.columns\n",
    "        ), f\"Target column '{self.target}' not found in the dataframe.\"\n",
    "\n",
    "        self.feature_labels = df.drop(columns=[self.target]).columns.tolist()\n",
    "\n",
    "        X = df.drop(columns=[self.target])\n",
    "        y = df[self.target]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            train_size=train_size,\n",
    "            random_state=42,\n",
    "            shuffle=shuffle,\n",
    "            stratify=y,\n",
    "        )\n",
    "\n",
    "        self.X = X_train if train else X_test\n",
    "        self.y = y_train if train else y_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X_dict = str(self.X.iloc[idx].to_dict())\n",
    "        y_value = self.target_values[self.y.iloc[idx].item()]\n",
    "        return X_dict, y_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:08<00:00,  1.45s/it]\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.45s/it]\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.45s/it]\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.45s/it]\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.45s/it]\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.45s/it]\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.45s/it]\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.45s/it]\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.46s/it]\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.46s/it]\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.46s/it]\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.46s/it]\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.46s/it]\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.46s/it]\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.46s/it]\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.47s/it]\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.47s/it]\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.46s/it]\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.46s/it]\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.46s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset = TitanicDataset(\"../dataset/titanic-dataset.csv\", train=False)\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "inference_model = InferenceModel(\"localhost\", port=23456)\n",
    "num_epochs = 20\n",
    "\n",
    "evaluation_results = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "    \n",
    "    for X, y in tqdm(data_loader):\n",
    "        prompts = process(X, \"Survived\", [\"DEAD\", \"ALIVE\"])\n",
    "        responses = inference_model.generate(prompts, {\"n\": 1, \"max_new_tokens\": 32})\n",
    "        y_preds = [parse(response) for response in responses]\n",
    "        \n",
    "        all_predictions.extend(y_preds)\n",
    "        all_true_labels.extend(y)\n",
    "    \n",
    "    evaluation_results.append((all_predictions, all_true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/20\n",
      "Run 2/20\n",
      "Run 3/20\n",
      "Run 4/20\n",
      "Run 5/20\n",
      "Run 6/20\n",
      "Run 7/20\n",
      "Run 8/20\n",
      "Run 9/20\n",
      "Run 10/20\n",
      "Run 11/20\n",
      "Run 12/20\n",
      "Run 13/20\n",
      "Run 14/20\n",
      "Run 15/20\n",
      "Run 16/20\n",
      "Run 17/20\n",
      "Run 18/20\n",
      "Run 19/20\n",
      "Run 20/20\n",
      "\n",
      "Performance - Summary Statistics across 20 runs:\n",
      "============================================================\n",
      "Accuracy Summary:\n",
      "  Mean           = 0.7009\n",
      "  Std Dev        = 0.0272\n",
      "  95% CI         = [0.6882, 0.7137]\n",
      "  Min / Max      = 0.6564 / 0.7560\n",
      "  LaTeX format   = 70.09% ± 2.72%\n",
      "\n",
      "Precision Summary:\n",
      "  Mean           = 0.7455\n",
      "  Std Dev        = 0.0236\n",
      "  95% CI         = [0.7345, 0.7566]\n",
      "  Min / Max      = 0.6963 / 0.7844\n",
      "  LaTeX format   = 74.55% ± 2.36%\n",
      "\n",
      "Recall Summary:\n",
      "  Mean           = 0.7009\n",
      "  Std Dev        = 0.0272\n",
      "  95% CI         = [0.6882, 0.7137]\n",
      "  Min / Max      = 0.6564 / 0.7560\n",
      "  LaTeX format   = 70.09% ± 2.72%\n",
      "\n",
      "F1 score Summary:\n",
      "  Mean           = 0.7028\n",
      "  Std Dev        = 0.0275\n",
      "  95% CI         = [0.6899, 0.7156]\n",
      "  Min / Max      = 0.6565 / 0.7583\n",
      "  LaTeX format   = 70.28% ± 2.75%\n",
      "\n",
      "Error rate Summary:\n",
      "  Mean           = 0.0718\n",
      "  Std Dev        = 0.0194\n",
      "  95% CI         = [0.0627, 0.0809]\n",
      "  Min / Max      = 0.0391 / 0.1117\n",
      "  LaTeX format   = 7.18% ± 1.94%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.utils import evaluate_multiple_runs\n",
    "\n",
    "evaluate_multiple_runs(evaluation_results, \"Performance\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
